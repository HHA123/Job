{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-white')\n",
    "import seaborn as sns\n",
    "sns.set_style(\"white\")\n",
    "%matplotlib inline\n",
    "\n",
    "from tqdm import tqdm_notebook, tnrange\n",
    "from itertools import chain\n",
    "\n",
    "from skimage.io import imread, imshow, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "#gpu_options = tf.GPUOptions(allow_growth=True,per_process_gpu_memory_fraction=0.333)\n",
    "#s = tf.InteractiveSession(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "\n",
    "#config=tf.ConfigProto(gpu_options=gpu_options)\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "\n",
    "#from tensorflow import keras\n",
    "#K = keras.backend\n",
    "\n",
    "##from tensorflow import keras\n",
    "K = keras.backend\n",
    "import keras, keras.layers as L\n",
    "#from keras import layers as L\n",
    "#from keras.models import Sequential\n",
    "from keras.layers import Input, Conv2D, Conv2DTranspose, MaxPooling2D, Concatenate, Dropout, BatchNormalization, UpSampling2D\n",
    "from keras.layers.core import Lambda, RepeatVector, Reshape\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import plot_model\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dropout, ZeroPadding2D\n",
    "from keras.layers.merge import concatenate\n",
    "\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.layers import Activation, Dense, Cropping2D\n",
    "from keras.layers import LeakyReLU, Flatten, UpSampling2D, Deconv2D\n",
    "from keras.models import Model\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import binary_crossentropy\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras import backend as kbackend \n",
    "\n",
    "\n",
    "\n",
    "#keras.backendckend.backend()\n",
    "#from tensorflow import keras\n",
    "#import keras.backend.tensorflow_backend as K\n",
    "\n",
    "#K.set_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"home/hampus/kaggle/tgssalt\"\n",
    "DIR = 'home/hampus/kaggle/tgssalt'\n",
    "path_train = \"home/hampus/kaggle/tgssalt/train\"\n",
    "path_test = 'home/hampus/kaggle/tgssalt/test'\n",
    "imgs_train = 'train/images'\n",
    "masks_train = 'train/masks'\n",
    "imgs_test = 'home/hampus/kaggle/tgssalt/test/images'\n",
    "\n",
    "IMG_SIZE = 101   # original/raw image size\n",
    "TGT_SIZE = 128   # model/input image size\n",
    "DPT_SIZE = 4     # CONV filter size when depth is input in model\n",
    "MAX_DEPTH = None # maximum depth('z') of seismic image, set after loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv', index_col=\"id\", usecols=[0])\n",
    "depths_df = pd.read_csv('depths.csv', index_col=\"id\")\n",
    "train_df = train_df.join(depths_df)\n",
    "test_df = depths_df[~depths_df.index.isin(train_df.index)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f767de9b7474f8aa35d102950a590de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_df[\"images\"] = [np.array(load_img('train/images/%s.png' % idx, grayscale=True)) / 255 \n",
    "                      for idx in tqdm_notebook(train_df.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd292ee1176e4336bc90b8a0c9276f7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_df[\"masks\"] = [np.array(load_img('train/masks/%s.png' % idx, grayscale=True)) / 255 \n",
    "                     for idx in tqdm_notebook(train_df.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "432f6fcf49cc4f36874a8384655d1cd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(101, 101)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_DEPTH = max(train_df[\"z\"])\n",
    "train_df[\"depth\"] = [np.ones_like(train_df.loc[i][\"images\"]) * train_df.loc[i][\"z\"] / MAX_DEPTH\n",
    "                     for i in tqdm_notebook(train_df.index)]\n",
    "train_df[\"depth\"][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 4)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>z</th>\n",
       "      <th>images</th>\n",
       "      <th>masks</th>\n",
       "      <th>depth</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>575d24d81d</th>\n",
       "      <td>843</td>\n",
       "      <td>[[0.525490196078, 0.513725490196, 0.5254901960...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[0.879040667362, 0.879040667362, 0.8790406673...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a266a2a9df</th>\n",
       "      <td>794</td>\n",
       "      <td>[[0.341176470588, 0.376470588235, 0.3333333333...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[0.827945776851, 0.827945776851, 0.8279457768...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75efad62c1</th>\n",
       "      <td>468</td>\n",
       "      <td>[[0.56862745098, 0.466666666667, 0.32549019607...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[0.488008342023, 0.488008342023, 0.4880083420...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34e51dba6a</th>\n",
       "      <td>727</td>\n",
       "      <td>[[0.541176470588, 0.474509803922, 0.3960784313...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[0.758081334724, 0.758081334724, 0.7580813347...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4875705fb0</th>\n",
       "      <td>797</td>\n",
       "      <td>[[0.0666666666667, 0.078431372549, 0.090196078...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[0.831074035454, 0.831074035454, 0.8310740354...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              z                                             images  \\\n",
       "id                                                                   \n",
       "575d24d81d  843  [[0.525490196078, 0.513725490196, 0.5254901960...   \n",
       "a266a2a9df  794  [[0.341176470588, 0.376470588235, 0.3333333333...   \n",
       "75efad62c1  468  [[0.56862745098, 0.466666666667, 0.32549019607...   \n",
       "34e51dba6a  727  [[0.541176470588, 0.474509803922, 0.3960784313...   \n",
       "4875705fb0  797  [[0.0666666666667, 0.078431372549, 0.090196078...   \n",
       "\n",
       "                                                        masks  \\\n",
       "id                                                              \n",
       "575d24d81d  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "a266a2a9df  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "75efad62c1  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "34e51dba6a  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "4875705fb0  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "\n",
       "                                                        depth  \n",
       "id                                                             \n",
       "575d24d81d  [[0.879040667362, 0.879040667362, 0.8790406673...  \n",
       "a266a2a9df  [[0.827945776851, 0.827945776851, 0.8279457768...  \n",
       "75efad62c1  [[0.488008342023, 0.488008342023, 0.4880083420...  \n",
       "34e51dba6a  [[0.758081334724, 0.758081334724, 0.7580813347...  \n",
       "4875705fb0  [[0.831074035454, 0.831074035454, 0.8310740354...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coverage(mask):\n",
    "    \"\"\"Compute coverage of salt mask \"\"\"\n",
    "    return np.sum(mask) / (mask.shape[0]*mask.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coverage_class(mask):\n",
    "    \"\"\"Compute class coverage of salt mask \"\"\"\n",
    "    if coverage(mask) == 0:\n",
    "        return 0\n",
    "    return (coverage(mask) * 100 //10).astype(np.int8) +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mem_used():\n",
    "    \"\"\"Memory used\"\"\"\n",
    "    import resource\n",
    "    return round(resource.getrusage(resource.RUSAGE_SELF)[2] * 10/1028 / 10, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1239.2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mem_used()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mem_fun(fun, **kwargs):\n",
    "    \"\"\"\"\"\"\n",
    "    mem_start = mem_used()\n",
    "    _ = fun(**kwargs)\n",
    "    print('memory used by function: {}mb'.format((mem_used() - mem_start)))\n",
    "\n",
    "nb_mem = mem_used()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMG_SIZE = 101   # original/raw image size\n",
    "#TGT_SIZE = 128   # model/input image size\n",
    "\n",
    "def upsample(img):\n",
    "    if IMG_SIZE == TGT_SIZE:\n",
    "        return img\n",
    "    return resize(img, (TGT_SIZE, TGT_SIZE), mode='constant', preserve_range=True)\n",
    "\n",
    "\n",
    "def downsample(img):\n",
    "    if IMG_SIZE == TGT_SIZE:\n",
    "        return img\n",
    "    return resize(img, (IMG_SIZE, IMG_SIZE), mode='constant', preserve_range=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1239.2"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mem_used()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"coverage\"] = train_df.masks.map(np.sum) / pow(IMG_SIZE, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def covrage_to_class(val):    \n",
    "    for i in range(11):\n",
    "        if val * 10 <= i :\n",
    "            return i\n",
    "        \n",
    "train_df[\"coverage_class\"] = train_df.coverage.map(covrage_to_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7f45946acc18>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4594735400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(15,5))\n",
    "sns.distplot(train_df.coverage, kde=False, ax=axs[0])\n",
    "sns.distplot(train_df.coverage_class, bins=10, kde=False, ax=axs[1])\n",
    "plt.suptitle(\"Salt coverage\")\n",
    "axs[0].set_xlabel(\"Coverage\")\n",
    "axs[1].set_xlabel(\"Coverage class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1248.4"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mem_used()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "468\n",
      "0.23\n"
     ]
    }
   ],
   "source": [
    "train_df['images'].shape[0]\n",
    "train_df['depth'].shape[0]\n",
    "print(train_df['z'][2])\n",
    "train_df['d'] = train_df.depth.map(np.max)\n",
    "train_df['d'] = np.round(train_df['d'],decimals=3)\n",
    "print(train_df['d'][-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle(matrix, target, testproc):\n",
    "    ratio = matrix.shape[0]/test_proportion\n",
    "    X_train = matrix[ratio:,:]\n",
    "    X_test =  matrix[:ratio,:]\n",
    "    Y_train = target[ratio:,:]\n",
    "    Y_test =  target[:ratio,:]\n",
    "    return X_train, X_test, Y_train, Y_test\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = shuffle(X, Y, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1248.4"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mem_used()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_valid, y_train, y_valid, cov_train, cov_test, depth_train, depth_test = train_test_split(\n",
    "    \n",
    "    #np.array(train_df.images.map(upsample).tolist()).reshape(-1, img_size_target, img_size_target, 1), \n",
    "    np.array(train_df.images.tolist()).reshape(-1,IMG_SIZE,IMG_SIZE,1),\n",
    "    #np.array(train_df.masks.map(upsample).tolist()).reshape(-1, img_size_target, img_size_target, 1),\n",
    "     np.array(train_df.masks.tolist()).reshape(-1,IMG_SIZE,IMG_SIZE,1),\n",
    "    train_df.coverage.values,\n",
    "    train_df.d.values,\n",
    "    test_size=0.15, stratify=train_df.coverage_class, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function keras.backend.tensorflow_backend.set_session(session)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def reset_tf_session():\n",
    "    K.clear_session()\n",
    "    tf.reset_default_graph()\n",
    "    #ses = K.get_session()\n",
    "    #return ses\n",
    "reset_tf_session()\n",
    "#s= tf.Session()\n",
    "#K.set_session\n",
    "keras.backend.set_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_2 (InputLayer)             (None, 101, 101, 1)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "zero_padding2d_4 (ZeroPadding2D) (None, 102, 102, 1)   0           input_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)               (None, 102, 102, 32)  320         zero_padding2d_4[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)              (None, 102, 102, 32)  0           conv2d_16[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)               (None, 102, 102, 32)  9248        dropout_5[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNorm (None, 102, 102, 32)  128         conv2d_17[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                   (None, 51, 51, 32)    9248        batch_normalization_5[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "zero_padding2d_5 (ZeroPadding2D) (None, 52, 52, 32)    0           conv1[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)               (None, 52, 52, 64)    18496       zero_padding2d_5[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)              (None, 52, 52, 64)    0           conv2d_18[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)               (None, 52, 52, 64)    36928       dropout_6[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNorm (None, 52, 52, 64)    256         conv2d_19[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2 (Conv2D)                   (None, 26, 26, 64)    36928       batch_normalization_6[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)               (None, 26, 26, 128)   73856       conv2[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)              (None, 26, 26, 128)   0           conv2d_20[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)               (None, 26, 26, 128)   147584      dropout_7[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNorm (None, 26, 26, 128)   512         conv2d_21[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv3 (Conv2D)                   (None, 13, 13, 128)   147584      batch_normalization_7[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "zero_padding2d_6 (ZeroPadding2D) (None, 14, 14, 128)   0           conv3[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)               (None, 14, 14, 256)   295168      zero_padding2d_6[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)              (None, 14, 14, 256)   0           conv2d_22[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)               (None, 14, 14, 256)   590080      dropout_8[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNorm (None, 14, 14, 256)   1024        conv2d_23[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv4 (Conv2D)                   (None, 14, 14, 256)   590080      batch_normalization_8[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTransp (None, 28, 28, 128)   131200      conv4[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "cropping2d_4 (Cropping2D)        (None, 26, 26, 128)   0           conv2d_transpose_4[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)               (None, 26, 26, 128)   147584      cropping2d_4[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)               (None, 26, 26, 128)   147584      conv2d_24[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_5 (Conv2DTransp (None, 52, 52, 64)    32832       conv2d_25[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)      (None, 52, 52, 128)   0           conv2d_transpose_5[0][0]         \n",
      "                                                                   batch_normalization_6[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)               (None, 52, 52, 64)    73792       concatenate_5[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)               (None, 52, 52, 64)    36928       conv2d_26[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "cropping2d_5 (Cropping2D)        (None, 51, 51, 64)    0           conv2d_27[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_6 (Conv2DTransp (None, 102, 102, 32)  8224        cropping2d_5[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)      (None, 102, 102, 64)  0           conv2d_transpose_6[0][0]         \n",
      "                                                                   batch_normalization_5[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "cropping2d_6 (Cropping2D)        (None, 101, 101, 64)  0           concatenate_6[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)               (None, 101, 101, 32)  18464       cropping2d_6[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)               (None, 101, 101, 32)  9248        conv2d_28[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)               (None, 101, 101, 1)   33          conv2d_29[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 2,563,329\n",
      "Trainable params: 2,562,369\n",
      "Non-trainable params: 960\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "inputs1 = Input((IMG_SIZE,IMG_SIZE,1))\n",
    "\n",
    "#First conv layer\n",
    "zeros1 = ZeroPadding2D(padding=((1,0),(1,0)))(inputs1)\n",
    "conv11 = Conv2D(32,kernel_size=(3, 3), strides =(1,1), activation=\"relu\", padding=\"same\")(zeros1)\n",
    "drop1 = Dropout(0.2)(conv11)\n",
    "conv12 = Conv2D(32,kernel_size=(3, 3), strides =(1,1), activation=\"relu\", padding=\"same\")(drop1)\n",
    "batch1 = BatchNormalization()(conv12)\n",
    "conv1 = Conv2D(32,kernel_size=(3, 3), strides =(2,2),activation=\"relu\",padding=\"same\",name=\"conv1\")(batch1)\n",
    "\n",
    "#Second conv layer\n",
    "zeros2 = ZeroPadding2D(padding=((1,0),(1,0)))(conv1)\n",
    "conv21 = Conv2D(64, kernel_size = (3,3), strides = ( 1,1), activation=\"relu\", padding=\"same\")(zeros2)\n",
    "drop2 = Dropout(0.3)(conv21)\n",
    "conv22 = Conv2D(64, kernel_size=(3,3), strides = (1,1), activation= \"relu\", padding = \"same\")(drop2)\n",
    "batch2 = BatchNormalization()(conv22)\n",
    "conv2 = Conv2D(64, kernel_size=(3,3), strides = (2,2), activation = \"relu\", padding = \"same\",name=\"conv2\")(batch2)\n",
    "\n",
    "\n",
    "#third conv layer\n",
    "#zeros3 = ZeroPadding2D(padding=((1,0),(1,0)))(conv2)\n",
    "conv31 = Conv2D(128, kernel_size = (3,3), strides = ( 1,1), activation=\"relu\", padding=\"same\")(conv2)\n",
    "drop3 = Dropout(0.3)(conv31)\n",
    "conv32 = Conv2D(128, kernel_size=(3,3), strides = (1,1), activation= \"relu\", padding = \"same\")(drop3)\n",
    "batch3 = BatchNormalization()(conv32)\n",
    "conv3 = Conv2D(128, kernel_size=(3,3), strides = (2,2), activation = \"relu\", padding = \"same\",name=\"conv3\")(batch3)\n",
    "\n",
    "\n",
    "#third conv layer\n",
    "zeros4 = ZeroPadding2D(padding=((1,0),(1,0)))(conv3)\n",
    "conv4 = Conv2D(256, kernel_size = (3,3), strides = ( 1,1), activation=\"relu\", padding=\"same\")(zeros4)\n",
    "drop4 = Dropout(0.5)(conv4)\n",
    "conv4 = Conv2D(256, kernel_size=(3,3), strides = (1,1), activation= \"relu\", padding = \"same\")(drop4)\n",
    "batch4 = BatchNormalization()(conv4)\n",
    "conv4 = Conv2D(256, kernel_size=(3,3), strides = (1,1), activation = \"relu\", padding = \"same\",name=\"conv4\")(batch4)\n",
    "\n",
    "\n",
    "#first upconv layer\n",
    "#up5 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(concatenate([Cropping2D(cropping=((1, 0), (1, 0)))(conv4), conv3], axis=3))\n",
    "up5 = Cropping2D(cropping=((1, 1), (1, 1)))(Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv4))\n",
    "con5 = concatenate([up5 , conv32], axis=3)\n",
    "conv5 = Conv2D(128, (3, 3), activation='relu', padding='same')(up5)\n",
    "conv5 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv5)\n",
    "#26x26\n",
    "\n",
    "#second upconv layer Cropping2D(cropping=((1, 1), (1, 1)))\n",
    "#up6 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv5), conv22], axis=3)\n",
    "#Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(concatenate([(conv5), conv2], axis=3))\n",
    "#conv6 = Conv2D(64, (3, 3), activation='relu', padding='same')(up6)\n",
    "#conv6 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv6)\n",
    "\n",
    "up6 = (Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv5))\n",
    "con6 = concatenate([up6 , batch2], axis=3)\n",
    "conv6 = Conv2D(64, (3, 3), activation='relu', padding='same')(con6)\n",
    "conv6 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv6)\n",
    "#52x52\n",
    "\n",
    "\n",
    "#third upconv layer\n",
    "up7 = (Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(Cropping2D(cropping=((1, 0), (1, 0)))(conv6)))\n",
    "con7 = concatenate([up7 , batch1], axis=3)\n",
    "crop7 = Cropping2D(cropping=((1, 0), (1, 0)))(con7)\n",
    "conv7 = Conv2D(32, (3, 3), activation='relu', padding='same')(crop7)\n",
    "conv7 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv7)\n",
    "\n",
    "\n",
    "output = Conv2D(1,kernel_size = (1,1),activation = 'sigmoid')(conv7)\n",
    "\n",
    "Unetmodel = Model(inputs = [inputs1],outputs =output)\n",
    "print(Unetmodel.summary())\n",
    "\n",
    "Unetmodel.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3126.6"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mem_used()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3400 samples, validate on 600 samples\n",
      "Epoch 1/200\n",
      "3392/3400 [============================>.] - ETA: 0s - loss: 0.4423 - acc: 0.7943Epoch 00000: val_loss improved from inf to 5.58186, saving model to ./keras.model\n",
      "3400/3400 [==============================] - 35s - loss: 0.4415 - acc: 0.7947 - val_loss: 5.5819 - val_acc: 0.2494\n",
      "Epoch 2/200\n",
      "3392/3400 [============================>.] - ETA: 0s - loss: 0.3301 - acc: 0.8748Epoch 00001: val_loss improved from 5.58186 to 2.73643, saving model to ./keras.model\n",
      "3400/3400 [==============================] - 27s - loss: 0.3297 - acc: 0.8750 - val_loss: 2.7364 - val_acc: 0.2494\n",
      "Epoch 3/200\n",
      "3392/3400 [============================>.] - ETA: 0s - loss: 0.3067 - acc: 0.8874Epoch 00002: val_loss improved from 2.73643 to 2.18683, saving model to ./keras.model\n",
      "3400/3400 [==============================] - 25s - loss: 0.3064 - acc: 0.8876 - val_loss: 2.1868 - val_acc: 0.2659\n",
      "Epoch 4/200\n",
      "3392/3400 [============================>.] - ETA: 0s - loss: 0.2755 - acc: 0.8989Epoch 00003: val_loss did not improve\n",
      "3400/3400 [==============================] - 24s - loss: 0.2755 - acc: 0.8990 - val_loss: 4.0998 - val_acc: 0.3480\n",
      "Epoch 5/200\n",
      "3392/3400 [============================>.] - ETA: 0s - loss: 0.2526 - acc: 0.9054Epoch 00004: val_loss improved from 2.18683 to 0.37181, saving model to ./keras.model\n",
      "3400/3400 [==============================] - 25s - loss: 0.2529 - acc: 0.9053 - val_loss: 0.3718 - val_acc: 0.8331\n",
      "Epoch 6/200\n",
      "3392/3400 [============================>.] - ETA: 0s - loss: 0.2447 - acc: 0.9109Epoch 00005: val_loss improved from 0.37181 to 0.29078, saving model to ./keras.model\n",
      "3400/3400 [==============================] - 25s - loss: 0.2446 - acc: 0.9109 - val_loss: 0.2908 - val_acc: 0.8852\n",
      "Epoch 7/200\n",
      "3392/3400 [============================>.] - ETA: 0s - loss: 0.2442 - acc: 0.9111Epoch 00006: val_loss improved from 0.29078 to 0.26185, saving model to ./keras.model\n",
      "3400/3400 [==============================] - 25s - loss: 0.2445 - acc: 0.9109 - val_loss: 0.2619 - val_acc: 0.9008\n",
      "Epoch 8/200\n",
      "3392/3400 [============================>.] - ETA: 0s - loss: 0.2298 - acc: 0.9158Epoch 00007: val_loss did not improve\n",
      "3400/3400 [==============================] - 24s - loss: 0.2294 - acc: 0.9160 - val_loss: 0.3558 - val_acc: 0.8877\n",
      "Epoch 9/200\n",
      "3392/3400 [============================>.] - ETA: 0s - loss: 0.2194 - acc: 0.9179Epoch 00008: val_loss did not improve\n",
      "3400/3400 [==============================] - 24s - loss: 0.2194 - acc: 0.9179 - val_loss: 0.2808 - val_acc: 0.8836\n",
      "Epoch 10/200\n",
      "3392/3400 [============================>.] - ETA: 0s - loss: 0.2160 - acc: 0.9196Epoch 00009: val_loss did not improve\n",
      "3400/3400 [==============================] - 24s - loss: 0.2159 - acc: 0.9196 - val_loss: 0.2685 - val_acc: 0.9101\n",
      "Epoch 11/200\n",
      "3392/3400 [============================>.] - ETA: 0s - loss: 0.2107 - acc: 0.9220Epoch 00010: val_loss improved from 0.26185 to 0.22637, saving model to ./keras.model\n",
      "3400/3400 [==============================] - 25s - loss: 0.2104 - acc: 0.9221 - val_loss: 0.2264 - val_acc: 0.9129\n",
      "Epoch 12/200\n",
      "3392/3400 [============================>.] - ETA: 0s - loss: 0.1948 - acc: 0.9262Epoch 00011: val_loss did not improve\n",
      "3400/3400 [==============================] - 24s - loss: 0.1945 - acc: 0.9264 - val_loss: 0.2538 - val_acc: 0.9060\n",
      "Epoch 13/200\n",
      "3392/3400 [============================>.] - ETA: 0s - loss: 0.1982 - acc: 0.9264Epoch 00012: val_loss improved from 0.22637 to 0.19739, saving model to ./keras.model\n",
      "3400/3400 [==============================] - 25s - loss: 0.1983 - acc: 0.9262 - val_loss: 0.1974 - val_acc: 0.9246\n",
      "Epoch 14/200\n",
      "3392/3400 [============================>.] - ETA: 0s - loss: 0.1822 - acc: 0.9318Epoch 00013: val_loss did not improve\n",
      "3400/3400 [==============================] - 24s - loss: 0.1820 - acc: 0.9319 - val_loss: 0.2251 - val_acc: 0.9190\n",
      "Epoch 15/200\n",
      "3392/3400 [============================>.] - ETA: 0s - loss: 0.1829 - acc: 0.9307Epoch 00014: val_loss did not improve\n",
      "3400/3400 [==============================] - 24s - loss: 0.1827 - acc: 0.9308 - val_loss: 0.2589 - val_acc: 0.9131\n",
      "Epoch 16/200\n",
      "3392/3400 [============================>.] - ETA: 0s - loss: 0.1778 - acc: 0.9323Epoch 00015: val_loss did not improve\n",
      "3400/3400 [==============================] - 24s - loss: 0.1776 - acc: 0.9324 - val_loss: 0.2151 - val_acc: 0.9140\n",
      "Epoch 17/200\n",
      "3392/3400 [============================>.] - ETA: 0s - loss: 0.1849 - acc: 0.9306Epoch 00016: val_loss did not improve\n",
      "3400/3400 [==============================] - 24s - loss: 0.1849 - acc: 0.9307 - val_loss: 0.2168 - val_acc: 0.9227\n",
      "Epoch 18/200\n",
      "3392/3400 [============================>.] - ETA: 0s - loss: 0.1716 - acc: 0.9352Epoch 00017: val_loss did not improve\n",
      "3400/3400 [==============================] - 24s - loss: 0.1717 - acc: 0.9351 - val_loss: 0.2138 - val_acc: 0.9148\n",
      "Epoch 19/200\n",
      "3392/3400 [============================>.] - ETA: 0s - loss: 0.1714 - acc: 0.9366Epoch 00018: val_loss improved from 0.19739 to 0.19678, saving model to ./keras.model\n",
      "3400/3400 [==============================] - 25s - loss: 0.1713 - acc: 0.9366 - val_loss: 0.1968 - val_acc: 0.9229\n",
      "Epoch 20/200\n",
      "3392/3400 [============================>.] - ETA: 0s - loss: 0.1723 - acc: 0.9376Epoch 00019: val_loss did not improve\n",
      "3400/3400 [==============================] - 24s - loss: 0.1722 - acc: 0.9376 - val_loss: 0.2323 - val_acc: 0.9091\n",
      "Epoch 21/200\n",
      "3392/3400 [============================>.] - ETA: 0s - loss: 0.1610 - acc: 0.9391Epoch 00020: val_loss did not improve\n",
      "3400/3400 [==============================] - 24s - loss: 0.1609 - acc: 0.9392 - val_loss: 0.3109 - val_acc: 0.8935\n",
      "Epoch 22/200\n",
      "3392/3400 [============================>.] - ETA: 0s - loss: 0.1574 - acc: 0.9383Epoch 00021: val_loss did not improve\n",
      "3400/3400 [==============================] - 24s - loss: 0.1573 - acc: 0.9384 - val_loss: 0.2755 - val_acc: 0.9032\n",
      "Epoch 23/200\n",
      "3392/3400 [============================>.] - ETA: 0s - loss: 0.1665 - acc: 0.9360Epoch 00022: val_loss did not improve\n",
      "3400/3400 [==============================] - 24s - loss: 0.1662 - acc: 0.9361 - val_loss: 0.2862 - val_acc: 0.9158\n",
      "Epoch 24/200\n",
      "3392/3400 [============================>.] - ETA: 0s - loss: 0.1610 - acc: 0.9398Epoch 00023: val_loss did not improve\n",
      "3400/3400 [==============================] - 24s - loss: 0.1616 - acc: 0.9395 - val_loss: 0.2080 - val_acc: 0.9242\n",
      "Epoch 25/200\n",
      "3392/3400 [============================>.] - ETA: 0s - loss: 0.1553 - acc: 0.9396Epoch 00024: val_loss did not improve\n",
      "3400/3400 [==============================] - 24s - loss: 0.1552 - acc: 0.9396 - val_loss: 0.3399 - val_acc: 0.8980\n",
      "Epoch 26/200\n",
      "3392/3400 [============================>.] - ETA: 0s - loss: 0.1571 - acc: 0.9410Epoch 00025: val_loss improved from 0.19678 to 0.17172, saving model to ./keras.model\n",
      "3400/3400 [==============================] - 25s - loss: 0.1580 - acc: 0.9407 - val_loss: 0.1717 - val_acc: 0.9351\n",
      "Epoch 27/200\n",
      "3392/3400 [============================>.] - ETA: 0s - loss: 0.1505 - acc: 0.9423Epoch 00026: val_loss did not improve\n",
      "3400/3400 [==============================] - 24s - loss: 0.1509 - acc: 0.9421 - val_loss: 0.2082 - val_acc: 0.9190\n",
      "Epoch 28/200\n",
      "3392/3400 [============================>.] - ETA: 0s - loss: 0.1457 - acc: 0.9441Epoch 00027: val_loss did not improve\n",
      "3400/3400 [==============================] - 24s - loss: 0.1456 - acc: 0.9442 - val_loss: 0.1839 - val_acc: 0.9332\n",
      "Epoch 29/200\n",
      "3392/3400 [============================>.] - ETA: 0s - loss: 0.1403 - acc: 0.9467Epoch 00028: val_loss did not improve\n",
      "3400/3400 [==============================] - 24s - loss: 0.1403 - acc: 0.9467 - val_loss: 0.1877 - val_acc: 0.9287\n",
      "Epoch 30/200\n",
      "3392/3400 [============================>.] - ETA: 0s - loss: 0.1340 - acc: 0.9472Epoch 00029: val_loss improved from 0.17172 to 0.17077, saving model to ./keras.model\n",
      "3400/3400 [==============================] - 25s - loss: 0.1342 - acc: 0.9471 - val_loss: 0.1708 - val_acc: 0.9333\n",
      "Epoch 31/200\n",
      "3392/3400 [============================>.] - ETA: 0s - loss: 0.1409 - acc: 0.9459Epoch 00030: val_loss did not improve\n",
      "3400/3400 [==============================] - 24s - loss: 0.1408 - acc: 0.9460 - val_loss: 0.2048 - val_acc: 0.9247\n",
      "Epoch 32/200\n",
      "3392/3400 [============================>.] - ETA: 0s - loss: 0.1329 - acc: 0.9488Epoch 00031: val_loss did not improve\n",
      "3400/3400 [==============================] - 24s - loss: 0.1329 - acc: 0.9488 - val_loss: 0.1793 - val_acc: 0.9365\n",
      "Epoch 33/200\n",
      "3392/3400 [============================>.] - ETA: 0s - loss: 0.1346 - acc: 0.9485Epoch 00032: val_loss did not improve\n",
      "3400/3400 [==============================] - 24s - loss: 0.1351 - acc: 0.9483 - val_loss: 0.2073 - val_acc: 0.9237\n",
      "Epoch 34/200\n",
      "3392/3400 [============================>.] - ETA: 0s - loss: 0.1549 - acc: 0.9417Epoch 00033: val_loss did not improve\n",
      "3400/3400 [==============================] - 24s - loss: 0.1548 - acc: 0.9418 - val_loss: 0.2432 - val_acc: 0.9108\n",
      "Epoch 35/200\n",
      "3392/3400 [============================>.] - ETA: 0s - loss: 0.1226 - acc: 0.9518Epoch 00034: val_loss did not improve\n",
      "3400/3400 [==============================] - 24s - loss: 0.1226 - acc: 0.9519 - val_loss: 0.2064 - val_acc: 0.9318\n",
      "Epoch 36/200\n",
      "3392/3400 [============================>.] - ETA: 0s - loss: 0.1280 - acc: 0.9504Epoch 00035: val_loss did not improve\n",
      "3400/3400 [==============================] - 24s - loss: 0.1286 - acc: 0.9502 - val_loss: 0.2247 - val_acc: 0.9194\n",
      "Epoch 37/200\n",
      "3392/3400 [============================>.] - ETA: 0s - loss: 0.1318 - acc: 0.9483Epoch 00036: val_loss did not improve\n",
      "\n",
      "Epoch 00036: reducing learning rate to 0.00010000000474974513.\n",
      "3400/3400 [==============================] - 25s - loss: 0.1317 - acc: 0.9483 - val_loss: 0.2080 - val_acc: 0.9263\n",
      "Epoch 38/200\n",
      "3392/3400 [============================>.] - ETA: 0s - loss: 0.1101 - acc: 0.9570Epoch 00037: val_loss did not improve\n",
      "3400/3400 [==============================] - 24s - loss: 0.1106 - acc: 0.9569 - val_loss: 0.1801 - val_acc: 0.9340\n",
      "Epoch 39/200\n",
      "3392/3400 [============================>.] - ETA: 0s - loss: 0.1052 - acc: 0.9592Epoch 00038: val_loss did not improve\n",
      "3400/3400 [==============================] - 24s - loss: 0.1053 - acc: 0.9591 - val_loss: 0.1863 - val_acc: 0.9325\n",
      "Epoch 40/200\n",
      "3392/3400 [============================>.] - ETA: 0s - loss: 0.1013 - acc: 0.9607Epoch 00039: val_loss did not improve\n",
      "3400/3400 [==============================] - 24s - loss: 0.1014 - acc: 0.9607 - val_loss: 0.1760 - val_acc: 0.9363\n",
      "Epoch 41/200\n",
      "3392/3400 [============================>.] - ETA: 0s - loss: 0.0983 - acc: 0.9622Epoch 00040: val_loss did not improve\n",
      "3400/3400 [==============================] - 24s - loss: 0.0982 - acc: 0.9622 - val_loss: 0.1723 - val_acc: 0.9366\n",
      "Epoch 00040: early stopping\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(patience=10, verbose=1)\n",
    "model_checkpoint = ModelCheckpoint(\"./keras.model\", save_best_only=True, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(factor=0.1, patience=6, min_lr=0.00001, verbose=1)\n",
    "\n",
    "epochs = 200\n",
    "batch_size = 32\n",
    "\n",
    "history = Unetmodel.fit(x_train, y_train,\n",
    "                    validation_data=[x_valid, y_valid], \n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    callbacks=[early_stopping, model_checkpoint, reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3358.7"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mem_used()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_iou(Y_true, Y_pred, score_thres=0.5):\n",
    "    \"\"\"Compute mean(IoU) metric\n",
    "    IoU = intersection / union\n",
    "    \n",
    "    For each (mask)threshold in provided range:\n",
    "     - convert probability mask to boolean mask based on given threshold\n",
    "     - score the mask 1 if(IoU > score_threshold(0.5))\n",
    "    Take the mean of the scoress\n",
    "\n",
    "    https://www.tensorflow.org/api_docs/python/tf/metrics/mean_iou\n",
    "    \"\"\"\n",
    "    prec = []\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        Y_pred_bool = tf.to_int32(Y_pred > t) # boolean mask by threshold\n",
    "        score, update_op = tf.metrics.mean_iou(Y_true, Y_pred_bool, 2)\n",
    "        K.get_session().run(tf.local_variables_initializer())\n",
    "        with tf.control_dependencies([update_op]):\n",
    "            score = tf.identity(score) #!! use identity to transform score to tensor\n",
    "        prec.append(score) \n",
    "        \n",
    "    return K.mean(K.stack(prec), axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test-gpu",
   "language": "python",
   "name": "tftest2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
